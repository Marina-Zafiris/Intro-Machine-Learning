{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K- Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbors algorithm or KNN for short is a very simple technique.\n",
    "The entire training dataset is stored. When a prediction is required, the k-most similar records to a new record from the training dataset are then located. From these neighbors, a summarized prediction is made.\n",
    "Once the neighbors are discovered, the summary prediction can be made by returning the most common outcome or taking the average. As such, KNN can be used for classification.\n",
    "\n",
    "KNN can be broken into three parts.\n",
    "\n",
    "1. Calculate Euclidean Distance\n",
    "2. Get Nearest Neighbors\n",
    "3. Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "This calculate the distance between two rows in a dataset.\n",
    "The formula is as follows\n",
    "\n",
    "$D(x^{1}, x^{2}) = \\sqrt{\\sum_{i}^{N}(x_{i}^{2}-x_{i}^{1})^{2}}$\n",
    "\n",
    "where, $x1$ is the first row of data, $x2$ is the second row of data and $i$ is the index to a specific column as we sum across all columns up to $N$. Bellow, is the formula impemented into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import sqrt\n",
    " \n",
    "# Calculate the Euclidean distance between two vectors, or rows in a dataset\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "    d = 0.0\n",
    "    \n",
    "    for i in range(len(row1)-1): \n",
    "        d += (row1[i] - row2[i])**2\n",
    "    return sqrt(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors\n",
    "Neighbors for a new piece of data in the dataset are the k closest instances, as defined by our distance measure.\n",
    "1. Calculate  the distance between record on dataset using Euclidean Distance\n",
    "2. Sort all of the records in the training dataset by their distance to the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def neighbors(train, test_row, k):\n",
    "    distance_list = list() # Initialize empty list of distances\n",
    "    \n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distance_list.append((train_row, dist))\n",
    "        \n",
    "    distance_list.sort(key=lambda tup: tup[1]) #ensures the second item of the tuple is used in the sort\n",
    "    neighbor_list = list()\n",
    "    for i in range(k):\n",
    "        neighbor_list.append(distance_list[i][0])\n",
    "    return neighbor_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "The most similar neighbors collected from the training dataset can be used to make predictions. The most represented class among the neighbors, can be found using the max() function in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a classification prediction with neighbors\n",
    "def knn(train, test_row, k):\n",
    "    \n",
    "    neighbor = neighbors(train, test_row, k)\n",
    "    output_values = [row[-1] for row in neighbor]\n",
    "    prediction = max(set(output_values), key=output_values.count) #takes the most frequent surrounding number\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing Iris Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = pd.read_csv('iris_data.csv')\n",
    "data_num = data.drop(['Species'], axis=1)\n",
    "df = shuffle(data_num) # We need a shuffled data set, not in decending class\n",
    "iris = np.array(df)\n",
    "\n",
    "training = iris[0:113] # 75% of the data\n",
    "testing = iris[113:151] # Remaining 25%\n",
    "\n",
    "test_data = np.delete(testing, np.s_[4], axis=1) # Removing the last column of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 97.2972972972973 %\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "counter = 0\n",
    "\n",
    "for i in range(len(test_data)): # \n",
    "    testrow = test_data[i]\n",
    "    label = knn(training, testrow, k) # Running predict classification\n",
    "    if label == testing[i, 4]: # Counting correct labeled data  \n",
    "        counter += 1\n",
    "\n",
    "print('Accuracy of the model:', (counter/len(test_data))*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
